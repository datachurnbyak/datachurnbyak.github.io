<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Data churn by AK - Principle of inference</title>

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" media="print" onload="this.media='all'">
<noscript>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap">
</noscript>



<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="manifest" href="/assets/manifest.json">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="theme-color" content="#f0f0f0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-title" content="Data churn by AK's App">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  <meta name="msapplication-TileColor" content="#2d89ef">
  <meta name="msapplication-starturl" content="/">
  <meta name="application-name" content="Data churn by AK's App">
  <meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">

    <meta name="keywords" content="Statistics, t-test, hypothesis testing, inference, null hypothesis, alternative hypothesis, distribution">

  <meta name="description" content="Principle of Inference explained clearly">
  <meta name="robots" content="index, follow">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Principle of inference">
<meta name="twitter:site" content="@amritkoirala1">
<meta name="twitter:description" content="Principle of Inference explained clearly">
<meta name="twitter:image" content="http://localhost:4000/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png">
<meta property="og:site_name" content="Data churn by AK">
<meta property="og:type" content="article">
<meta property="og:title" content="Principle of inference">
<meta property="og:description" content="Principle of Inference explained clearly">
<meta property="og:url" content="http://localhost:4000/posts/2022-01-13-Principle-of-inference">
<meta property="og:image" content="http://localhost:4000/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png">
  <meta property="article:author" content="Amrit Koirala">
  <meta property="article:published_time" content="2022-01-12T17:11:06-06:00">
  <meta property="article:modified_time" content="2022-01-12T17:11:06-06:00">
  <meta property="article:section" content="Statistics">
  <meta property="article:tag" content="t-test">
  <meta property="article:tag" content="hypothesis testing">
  <meta property="article:tag" content="inference">
  <meta property="article:tag" content="null hypothesis">
  <meta property="article:tag" content="alternative hypothesis">
  <meta property="article:tag" content="distribution">
  <script type="application/ld+json">{
  "@context": "https://schema.org"
  ,"@graph": [
    {
      "@type": "Person"
      ,"@id": "http://localhost:4000/#person"
      ,"name": "Amrit Koirala"
      ,"url": "http://localhost:4000/tabs/about.html"
      ,"image": "http://localhost:4000/assets/img/about/about.jpg"
      ,"description": "Data churn by AK is Amrit Koirala's journey in bioinformatics and data science."
  },{
    "@type": "WebSite"
    ,"@id": "http://localhost:4000/#website"
    ,"url": "http://localhost:4000/"
    ,"name": "Data churn by AK"
    ,"description": "Data churn by AK is Amrit Koirala's journey in bioinformatics and data science."
    ,"publisher": {"@id": "http://localhost:4000/#person"}
    ,"inLanguage": "en-US"
    ,"sameAs": ["https://www.github.com/akoirala2000","https://www.linkedin.com/in/amrit-koirala-41037392","https://www.twitter.com/amritkoirala1"]
    ,"copyrightHolder" : {"@id": "http://localhost:4000/#person"}
    ,"copyrightYear" : "2022"
  },{
    "@type": "WebPage"
    ,"@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#webpage"
    ,"url": "http://localhost:4000/posts/2022-01-13-Principle-of-inference"
    ,"name": "Principle of inference"
    ,"isPartOf": {"@id": "http://localhost:4000/#website"}
    ,"breadcrumb": {"@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#breadcrumb"}
    ,"primaryImageOfPage": "http://localhost:4000/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png"
    ,"datePublished": "2022-01-12T17:11:06-06:00"
    ,"dateModified": "2022-01-12T17:11:06-06:00"
    ,"description": "Principle of Inference explained clearly"
    ,"inLanguage": "en-US"
    ,"potentialAction": {
      "@type": "ReadAction"
      ,"target": "http://localhost:4000/posts/2022-01-13-Principle-of-inference"
    }
  },{
      "@type": "BreadcrumbList",
      "@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#breadcrumb",
      "itemListElement": [
        {
          "@type": "ListItem"
          ,"position": 1
          ,"name": "Home"
          ,"item": "http://localhost:4000/"
        },
        {
          "@type": "ListItem"
          ,"position": 2
          ,"name": "Notes"
          ,"item": "http://localhost:4000/tabs/blog/"
        },
        {
          "@type": "ListItem"
          ,"position": 3
          ,"name": "Principle of inference"
        }
      ]
    },{
      "@type": "BlogPosting"
      ,"@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#content"
      ,"isPartOf": {"@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#webpage"}
      ,"mainEntityOfPage": {"@id": "http://localhost:4000/posts/2022-01-13-Principle-of-inference#webpage"}
      ,"publisher": {"@id": "http://localhost:4000/#person"}
      ,"author": {"@id": "http://localhost:4000/#person"}
      ,"inLanguage": "en-US"
      ,"headline": "Principle of inference"
      ,"image": "http://localhost:4000/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png"
      ,"thumbnailUrl": "http://localhost:4000/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png"
      ,"datePublished": "2022-01-12T17:11:06-06:00"
      ,"dateModified": "2022-01-12T17:11:06-06:00"
      ,"articleSection": ["Statistics", "t-test", "hypothesis testing", "inference", "null hypothesis", "alternative hypothesis", "distribution"]
      ,"description": "Principle of Inference explained clearly"
      ,"copyrightHolder" : {"@id": "http://localhost:4000/#person"}
      ,"copyrightYear" : "2022"
      ,"wordCount": 4726
      ,"articleBody": "Introduction Is the height of male (Age group 20-39 years old) in North America greater than 5.5 ? Is the average height of male (Age group 20-39 years old) in North America greater than 5.5 ? What is the average height of male (Age group 20-39 years old) in North America, Europe, and Asia ? Is the average height of male (Age group 20-39 years old) in North America different than in Europe or Asia ? We often see similarly formatted questions statistics and use the concepts of inference and hypothesis testing to solve them. Inference and Hypothesis testing are the two most important and the most confusing concepts in statistics. Inference is related to estimating the population parameters from a sample. Hypothesis testing as its name suggests is a two step process, first is to build a hypothesis and second is to test how well our data support that hypothesis. Inference and hypothesis testing are highly interdependent on each other because the need to build a hypothesis before testing rises because we had to use inference in the first place. Therefore, the best way to understand them is by learning them together but understanding the fine differences between each other at the same time. We will decipher this mystery by solving to questions listed above by two different approach. First approach is a hypothetical situation where we will not use any inference and study the whole population while in the second approach we will do orthodox sampling and hypothesis testing. Without using inference Population is a data set representing all the entity of interest. For example: If we are interested in study of distribution of facebook users by country then, all 2.912 billion facebook users (facebook data 2022) constitute the population. At the same time if we are interested in distribution of facebook users in USA by state, then the facebook users in USA (307.34 million) constitute the population. Similarly, if we are interested in effect of age on hypertension in human being, then every single human being in world (7.9 billion, 2022) constitute our population. In situations where we are interested in small population like comparing the performance of two high school senior students only, we can make measurement on all students and compare the mean performance score in each school but such study will have very narrow scope and that result cannot be generalized to any other schools. Measurements made on a population are called parameters and mean is denoted by \\(\\mu\\) and variance is denoted as \\(\\sigma^2\\). Now lets dive into our questions. If we are not going to use inference then we do not have our favorite option of sampling, we are forced to study the whole population. After some google search I could figure out that there are 450, 105 and 75 million males of this age group in Asia, Europe and North America respectively and each of these constitute a population for this question. Therefore, we will first need to find the height of each of these millions of people from each continent. We can simulate such population in R by generating a dummy population of such size and also calculate the mean, standard deviation and distribution for each population (Figure 1). Even for R, processing such large sized vector took quite a while, imagine you had to do this in reality. How much resource, money, time, and bookkeeping you would need to accomplish this? code here set.seed(578) Asia &lt;- rnorm(4.5e8, mean=5, 0.2) NorA &lt;- rnorm(7.5e+07, mean=6.2, 0.4) Euro &lt;- rnorm(1.05e+08, mean= 5.7, 0.3) mean_Asia &lt;- mean(Asia) var_Asia &lt;- var(Asia) hist_asia &lt;-hist(Asia, breaks = 200, plot=FALSE) mean_NorA &lt;- mean(NorA) var_NorA &lt;- var(NorA) hist_NorA &lt;- hist(NorA, breaks= 200, plot=FALSE) mean_Euro &lt;- mean(Euro) var_Euro &lt;- var(Euro) hist_Euro &lt;- hist(Euro, breaks= 200, plot=FALSE) plot(hist_asia, border=\"blue\", col=NULL, xlim = c(4.2,7.5), xlab = \"Continent\", main=\"Distribution of height of male aged 20-39 in 3 different continents\") plot(hist_NorA, border = \"red\", col=NULL, add=TRUE) plot(hist_Euro, border= \"darkgreen\", col=NULL, add=TRUE) legend(5.5,8e6, legend = c(paste0(\"Asia (mean = \",round(mean_Asia,1), \", sd= \",round(sqrt(var_Asia),3),\")\" ), paste0(\"Europe (mean = \",round(mean_Euro,1), \", sd= \",round(sqrt(var_Euro),1),\")\" ), paste0(\"North America (mean = \",round(mean_NorA,1), \", sd= \",round(sqrt(var_NorA),1),\")\" )), fill= c(\"blue\", \"darkgreen\", \"red\")) done! For now lets assume, R did all that hard work for us and we have necessary data we wanted to collect and we can focus on the answers to the question above: Is the height of male (Age group 20-39 years old) in North America greater than 5.5 ? We can see from figure 1 that most of the heights in North America is greater than 5.5. It may be tempting to answer “Yes” to this question but if we do so, we will be wrong because all the heights in North America are not above 5.5 (there is small proportion of heights in N America below 5.5). The alternative is to first calculate the probability of finding a height less than 5.5 (\\(\\alpha\\)) in N America and re-phrase our answer as “the height in N America is greater than 5.5 but the probability that this is incorrect is \\(\\alpha\\). The smaller this \\(\\alpha\\) aka significance level or p-value gets there is more certainty in our answer. The generally acceptable value of \\(\\alpha\\) is &lt; 0.05. Since, we already know mean and sd of all these three population we can plug these number in pdf of normal distribution in R to find these p-values and also visualize the probability we are calculating as the area under the curve (figure 2). For details about probability distribution and how to calculate probabilities for normally distributed random variable see my notes on normal distribution and binomial distribution). code here cat(\"Probability that heights in N. America is less that 5.5 is = \", pnorm(5.5, mean= mean_NorA, sd= sqrt(var_NorA)), \"\\n\") cat(\"Probability that heights in Europe is less that 5.5 is = \", pnorm(5.5, mean= mean_Euro, sd= sqrt(var_Euro)), \"\\n\") cat(\"Probability that heights in Asia is less that 5.5 is = \", pnorm(5.5, mean= mean_Asia, sd= sqrt(var_Asia)), \"\\n\") curve(dnorm(x, mean=5, sd=0.2), from = 4,to= 7.5, col= \"blue\", ylab= \"density\", xlab=\"height(in)\") polygon(c(seq(4, 5.5, 0.05),5.5), c(dnorm(seq(4, 5.5, 0.05), mean =5, sd=0.2),0), col=\"lightblue\") curve(dnorm(x, mean=5.7, sd=0.3), col= \"darkgreen\",add=T) polygon(c(seq(4, 5.5, 0.05),5.5), c(dnorm(seq(4, 5.5, 0.05), mean =5.7, sd=0.3),0), col=\"lightgreen\") curve(dnorm(x, mean=6.2, sd=0.4), col= \"red\", add=T) polygon(c(seq(4, 5.5, 0.05),5.5), c(dnorm(seq(4, 5.5, 0.05), mean =6.2, sd=0.4),0), col=\"red\") curve(dnorm(x, mean=5, sd=0.2), col=\"blue\", add = T) legend(5.6,2, legend = c(paste0(\"Asia (mean = \",round(mean_Asia,1), \", sd= \",round(sqrt(var_Asia),3),\")\" ), paste0(\"Europe (mean = \",round(mean_Euro,1), \", sd= \",round(sqrt(var_Euro),1),\")\" ), paste0(\"North America (mean = \",round(mean_NorA,1), \", sd= \",round(sqrt(var_NorA),1),\")\" )), fill= c(\"blue\", \"darkgreen\", \"red\")) done! ## Probability that heights in N. America is less that 5.5 is = 0.04006165 ## Probability that heights in Europe is less that 5.5 is = 0.2524402 ## Probability that heights in Asia is less that 5.5 is = 0.9937895 Using the p-values we can now give the complete answer; Yes, the height of male (Age group 20-39 years old) in N America is greater than 5.5 ft, given that this may be wrong 4% of the time. This 4% is below the generally accepted level of 5% error rate. Therefore, if a jeans manufacturer in N. America makes pants for height only above 5.5 ft, majority of man in N. America can find pants of their size. While a similar company in Europe would never want to manufacture pants that fit only above 5.5 ft because one fourth of its customers won’t be able to use that. Similarly, such company in Asia will manufacture pants that will fit heights less than 5.5 ft only. Therefore, although the answer we get using statistics may sound like incomplete information it has a lot of practical application when the result needs to be implemented in a large population. Lets review what we did here because it forms the foundation of any hypothesis testing. When the underlying distribution of a random variable (Y) is known, for any value of that random variable (y), we can find the probability of observing values more extreme than that value(y). If that probability is very small, then we can say, that value(y) itself is very rear in this distribution and could belong to other distribution. To take an example from the problem we are working with, we saw that probability getting a height greater than 5.5 in Asia is extremely low (0.00063). Therefore, if we randomly sample a man from the whole world and his height is found to be 5.5, then we can very confidently (probability of error is only 0.00063) say he is not from Asia. Does this mean he belong to N America? Or Europe? No, we will never know that answer but the point is when we properly select the random variable(Y) (sample mean, difference of sample mean, sample variance, sample proportion etc. ) and ask the correct question we can get some very useful answers about question of interest. Once we understand this we will later see how aptly early statisticians have devised hypothesis testing to get best out of it. Is the average height of male (Age group 20-39 years old) in North America greater than 5.5 ? Since we have made measurements on every man in that age group we can find the true mean by calculating sum of all the heights in a continent and divide by the population size of that continent which R already did for us. The mean height in N America is 6.2. This is true mean of this population so we do not need to make any estimate or confidence intervals to say that mean height in N America is greater that 5.5. What is the average height of male (Age group 20-39 years old) in North America, Europe, and Asia ? Similar to question no. 2, since we have complete population data, we can say with 100% confidence that mean height in N America, Europe and Asia is 6.2, 5.7 and 5 respectively. Is the average height of male (Age group 20-39 years old) in North America different than in Europe or Asia ? Answer to this is also straight forward. From question no 3 we can see clearly, they are different for these three populations. We saw, many of these questions could be easily answered because we could measure each and every man and get true mean \\((\\mu)\\) and sd \\((\\sigma)\\) for these populations. But recall again how arduous that task could be and the real-world situation is even more complicated by the fact that most populations we need to study have infinite numbers of entities, so it is impossible to find the true population parameters. This is where inference shines in. Inference provides the unbiased estimate of the population parameters using the information from a sample of certain size (n) from that population. Now, that we know the complications of studying the whole population we will see below, how we can deal with our question in much practical way using principles of inference and hypothesis testing, but first lets understand how inference works in general. Statistical inference sample is a subset of population (size = n) and is unbiased representation of the population. If n= \\(\\infty\\), sample behaves like the population and if n = 1, sample is just one observation from the population. It is very important for sample to be a representative of population because ultimately measurements made on a sample will be used to infer the population parameter. Any measurements made on a sample is called statistic (note statistics is branch of mathematics which study these statistic). For example sample mean (\\(\\bar x\\)) and sample variance (\\(s^2\\)) Sample is the main workhorse of statistics. This is all we have to make inference about population parameters. Usually a sample used to make inference on population parameters is much smaller in size than the population itself so it is very convenient to collect data (statistic) on a sample but this convenience comes at some cost, which is uncertainty associated with the estimate. We will see later, this uncertainty depend on population variance and we can tackle it by increasing sample size (n). Fortunately, in many real life situation, a sample of small size gives an estimate of population parameters with high precision. Therefore in a statistical analysis, sample statistic is used to make a statement about the population parameter which is always accompanied by a degree of precision (or chances of making an error). In situations where, the precision is relatively high (chances of making an error is low) we trust that statement and interpret our experiment based off that statement about population. On the other hand, if precision is low (chances of making an error is high), we do not trust that statement about population, so we cannot make any interpretation about the experiment or question of interest. The widely accepted level of that accuracy in scientific community is above 95% (or less than 5% chances of making an error). Inference framework Statistical inference uses very complex mathematical models to build a framework which will take the information from a sample of finite size (n) as an input and output estimate of parameters for the population of infinite size (along with degree of uncertainty). Then we can use these estimates of population parameters for the purpose of hypothesis testing or other interpretation downstream. Although, we are not interested in details of the mathematical models we must see what are the major components of this framework and how it process the information from a sample and what assumptions must be satisfied for the results from this framework to be valid. code here #population defined by mean and variance poplist &lt;- list(pop1=c(5, 0.04) , pop2= c(5.7, 0.0898), pop3 = c(6.2, 0.1599)) pop_col = c(\"blue\", \"darkgreen\", \"red\") plot(x=0,y=0,xlim= c(4,7.5), ylim=c(0,2), pch=NULL, ylab= \"density\", main=\"Distribution of 3 populations\", yaxt=\"n\") for(i in seq_along(poplist)){ curve(dnorm(x, mean=poplist[[i]][1], sd=sqrt(poplist[[i]][2])), col=pop_col[i], lwd=2,add=T) } #Standardized normal curve curve(dnorm(x), from = -4,to= +4, ylab= \"density\", xlab= \"z\", main= \"Standard normal distribution\", yaxt=\"n\", lwd=1.7) ##Sampling distribution of sample mean sample_size &lt;- c(5, 15, 25, 50) sample_colors &lt;- list(pop1= c(\"#89CFF0\",\"#6495ED\",\"#6082B6\",\"#5D3FD3\"), pop2= c(\"#AFE1AF\",\"#50C878\",\"#008000\",\"#355E3B\"), pop3= c(\"#F88379\",\"#C04000\",\"#E30B5C\",\"#A52A2A\")) plot(x=0,y=0,xlim= c(4,7.5), ylim=c(0,13), pch=NULL,xlab=\"sample mean\", ylab= \"density\", main=\"Sampling distribution of sample mean\", yaxt=\"n\") for(i in seq_along(poplist)){ for(sample in seq_along(sample_size)){ curve(dnorm(x, mean=poplist[[i]][1], sd=sqrt(poplist[[i]][2]/sample_size[sample])), col=sample_colors[[i]][sample],lwd=1.7, add=T) } } ###sampling distribution of sample variance # When sample size is close to 30 or more chi square distribution is similar to normal distribution plot(x=0,y=0,xlim= c(0,0.4), ylim=c(0,24), pch=NULL,xlab=\"sample variance\", ylab= \"density\", main=\"Sampling distribution of sample varaince \", yaxt=\"n\") for(i in seq_along(poplist)){ for(sample in 3:4){ curve(dnorm(x, mean=poplist[[i]][2], sd=sqrt((poplist[[i]][2])^2/(sample_size[sample]-1)*2)), col=sample_colors[[i]][sample],lwd=1.7, add=T) } } ####Plot chisquare for distribution plot(x=0,y=0,xlim= c(0,65), ylim=c(0,0.2), pch=NULL,xlab=\"Chi square\", ylab= \"density\", main=\"Chi-square distribution \", yaxt=\"n\") linecol &lt;- rainbow(4) size = c(5,15,25,50) for(i in 1:length(size)){ curve(dchisq(x, df=size[i]-1), from = 0,to= 65, col= linecol[i], add = T, lwd=1.7) } legend(30,0.2, legend = c( paste0(\"df = \", size-1 )), col= c(linecol), lty= c(1,1,1,1)) ###Plot t-distribution plot(x=0,y=0,xlim= c(-4,4), ylim=c(0,0.4), pch=NULL,xlab=\"t-statistic\", ylab= \"density\", main=\"t-distribution \", yaxt=\"n\") linecol &lt;- rainbow(4) size = c(5,15,25,50) for(i in 1:length(size)){ curve(dnorm(x), from = -4,to= 4, col= \"darkgreen\", ylab= \"density\", add=T, lwd=1.7) curve(dt(x, df=size[i]-1), from = -4,to= 4, col= linecol[i], add = T, lwd=1.7) } legend(2,0.4, legend = c(\"Std. Normal\", paste0(\"df = \", size-1 )), col= c(\"darkgreen\",linecol), lty= c(1,1,1,1,1)) ##### F-distribution plot(x=0,y=0,xlim= c(0,3), ylim=c(0,1.5), pch=NULL,xlab=\"F-statistic\", ylab= \"density\", main=\"F-distribution \", yaxt=\"n\") linecol &lt;- rainbow(4) size1 = c(5,15,25,50) size2 = c(10,23,4,50) for(i in 1:length(size)){ curve(df(x, df1=size1[i]-1, df2=size2[i]-1), col= linecol[i], add = T, lwd=1.7) } legend(2,1, legend = c( paste0(\"df1 = \", size1-1, \", df2 = \", size2-1 )), col= c(linecol), lty= c(1,1,1,1)) done! We need to acknowledge that population parameters (\\(\\mu\\)) and (\\(\\sigma^2\\)) are fixed and universal quantity and we will never know its true value (We will use the true population parameters calculated in first step to compare results from the inference only). The ultimate goal of inference is to get best estimate of these two parameters using only statistic calculated from a sample of size n. The major components of the statistical framework are shown in figure 3. The population with mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)) is on the top of this framework and it is represented by distribution of random variable we are interested in (Example height of male aged between 20-39). The most important assumption about the population is that it follows normal distribution hence a standard normal distribution curve can be used to find probabilities related to the population. Two most important statistic we measure on a sample is sample mean \\((\\bar x)\\) and sample variance \\((s^2)\\). Central Limit Theorem gives the distribution of sampling distribution of sample mean which states that sample mean are also normally distributed and mean of such distribution is also population mean (\\(\\mu\\)), but has less variance than the population variance (figure 3) given by \\(\\frac{\\sigma^2}{n}\\). Therefore, larger the sample size gets less is the variance (shown by darker color for each population in figure 3). To get the probability associated with this distribution we can do a z-scale transformation for which we need population mean \\(\\mu\\) and population variance \\(\\sigma^2\\). \\(z= \\frac{\\bar Y- \\mu}{\\frac{\\sigma}{\\sqrt n}}\\) Hypothesis testing is designed in such a way that we will our question will have the population mean but we should be able to estimate the population variance using the sample variance. The top left plot in figure 3 show the distribution of sample variance. It is found that sample variance follows Chi-squared \\(\\chi ^2\\) distribution. Which shows, mean of the distribution of sample variance is population variance but unlike when the sample size is small it is heavily skewed on the left. Which means sample variance calculated from a random sample of small size most probably gives the underestimate of the population variance. \\(\\chi ^2\\) distribution accounts for this discrepancy by providing separate distribution for samples of different size. To include this information in our z-score calculation a new statistic is calculated called t-statistic which follows t-distribution and similar to \\(\\chi^2\\) distribution it has different distribution for different sample size. Both \\(\\chi^2\\) and t-distribution is same as normal distribution when that sample size is greater than 30. Once we have this t-statistic we can use the probability given by t-distribution to find any probability associated with sampling distribution of sample means. \\[t-statistic = \\frac{\\bar Y- \\mu}{\\frac{s}{\\sqrt n}}\\] As you can see the all the variables in the equation can be calculated using a sample which enables us to compare the sample mean with the mean given in the question. The above method works best only when we need to compare two means. When we need to compare means from more than one population ANOVA is used for which inference framework has F-distribution which is basically ratio of two variance. If the variance is equal it has a value of 1 other wise it will be greater than 1. Details in ANOVA. Application Now that we have seen the basic components of inference (please see notes focused on each distribution to learn more about them) we can again revisit our questions. Is the height of male (Age group 20-39 years old) in North America greater than 5.5 ? We could answer this question in much detail when we had the distribution of heights (defined by population mean and variance) in hand. But now we do not know population parameters hence inference is not able to provide answer to this question but we can still answer other questions below. Is the average height of male (Age group 20-39 years old) in North America greater than 5.5 ? Lets recall what we learned about hypothesis testing in the beginning. If we know the underlying distribution of a random variable we can check, how unusual a given value is to that distribution and if it is indeed very rare to observe that value in given distribution we can conclude, that value does not belong to the given distribution. In hypothesis testing we do exactly same but in little twisted way to be able to use the inference framework discussed above. In this setup we make a null hypothesis and it is exactly opposite to what we want in our question of interest. So why we need this null hypothesis? To answer this, lets see what is our question and what information we have about our population. Since we are not measuring every man living in N America, all we can do is measure heights in a randomly selected sample of size(n). Then, the mean we calculate from this sample(\\(\\bar x\\)) is just one value in the sampling distribution of the sample mean for this population. We cannot calculate t-statistic with just sample mean and sample variance. We need the population mean. The question is giving us some clue. We need to first see that there are two populations in this question. The height of male (Age group 20-39 years old) in N America is first and obvious population we have been seeing from the beginning but the number we are tying to compare (5.5) is actually mean of a hypothetical population. Therefore, if we cannot find population mean for our population, we can assume that our sample is taken from that hypothetical population (for which mean is given by the question) and check how unusual is this sample mean in that hypothetical population? If it comes out to be a rare event than we can reach to the conclusion that our sample does not belong to that hypothetical population. What we are doing by assuming our sample came from that hypothetical population given by question is building a null hypothesis. And at the end of the test we want to see the sample mean we get from our sample, to be a rare event for that hypothetical population. Which means we reject null hypothesis. To formally do this we first state the null hypothesis (\\(H_o\\)) and alternate hypothesis (\\(H_1\\)) \\[H_o: \\mu = 5.5\\] \\[H_1: \\mu &gt;5.5\\] Then calculate the t-statistic \\(t =\\frac{\\bar x - 5.5}{\\frac{s}{\\sqrt n}}\\) ##Lets first make a sample of 100 from the population of NoA set.seed(45) set1 &lt;- sample(NorA, 100) cat(\"The t-statistic for this test is = \",(mean(set1)-5.5)/sqrt(var(set1)/100), \"\\n\") ## The t-statistic for this test is = 18.31421 cat( \"The p-value for this test is = \",pt((mean(set1)-5.5)/sqrt(var(set1)/100), 99, lower.tail = FALSE), \"\\n \\n\") ## The p-value for this test is = 7.324508e-34 ## cat(\"##########--USING R t.test FUNCTION --########\\n\") ## ##########--USING R t.test FUNCTION --######## t.test(set1, mu= 5.5, alternative = \"greater\") ## ## One Sample t-test ## ## data: set1 ## t = 18.314, df = 99, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is greater than 5.5 ## 95 percent confidence interval: ## 6.147978 Inf ## sample estimates: ## mean of x ## 6.212581 ##visualize ##BIG ASSUMPTION JUST FOR VISUALIZATION #for hypothetical population the variance is assumed to be equal to sample variance (just an approximation to see big picture ) plot(x=0,y=0,xlim= c(3,9), ylim=c(0,11), pch=NULL, ylab= \"density\", main=\"Distribution null hypothesis and alternative\", yaxt=\"n\") curve(dnorm(x, mean=6.2, sd= sqrt(var_NorA)), col=\"#f4c2c2\", lwd=2,add=T) curve(dnorm(x, mean=6.2, sd= sqrt(var_NorA/100)),n=500, col=\"red\", lwd=2,add=T) curve(dnorm(x, mean=5.5, sd= sqrt(var(set1))), col=\"#d2d1f9\", lwd=2,add=T) curve(dnorm(x, mean=5.5, sd= sqrt(var(set1)/100)), n=500,col=\"purple\", lwd=2,add=T) abline(v=5.5, col=\"#d2d1f9\" ) abline(v=6.2, col=\"#f4c2c2\", lwd=2 ) abline(v= mean(set1)) In the figure 4 we can clearly see, why p-value is so small. The distribution with green shade and the green dot at 6.21 are the only one distribution and data that given to us by the question. The alternative hypothesis and other populations are shown using the data we collected from first section just to show big picture. What is the average height of male (Age group 20-39 years old) in North America, Europe, and Asia ? In absence of the knowledge of true population mean, the mean we get from a sample is the best estimate of the true population mean. But given the inherent variability in the sampling distribution of sample means there will be some level of uncertainty. To account for this instead of reporting the point estimate, we find a interval at certain significance level based of the sample mean. Lets start with North America, we will again randomly take a sample of size(n)= 50. And calculate the sample mean of this sample. Since we do not know the population mean, we will need to assume the population mean is sample mean in this sample and based off the distribution centered around this sample mean we will calculate the range of sample means which is encompass 95% of the sample means(exclude only 2.5% means on both extremes of distribution). Narrower this interval is better is the quality. The interpretation for CI at 95% significane is 95% of the times we construct such intervals, true means will be within that interval. set.seed(100) set2 &lt;- sample(NorA, 50) mean_set2 &lt;- mean(set2) mean_set2 - (qt(0.025, 49, lower.tail = FALSE)*sqrt(var(set2)/50)) ## [1] 6.169956 mean_set2 + (qt(0.025, 49, lower.tail = FALSE)*sqrt(var(set2)/50)) ## [1] 6.405479 #Results can be confirmed by doing a test test for this mean t.test(set2, mu= mean_set2, alternative = \"two.sided\") ## ## One Sample t-test ## ## data: set2 ## t = 0, df = 49, p-value = 1 ## alternative hypothesis: true mean is not equal to 6.287718 ## 95 percent confidence interval: ## 6.169956 6.405479 ## sample estimates: ## mean of x ## 6.287718 ##visualize ##BIG ASSUMPTION JUST FOR VISUALIZATION #for unknow population with mean equal to sample mean the variance is assumed to be equal to sample variance (just an approximation to see big picture ) plot(x=0,y=0,xlim= c(5,7.3), ylim=c(0,11), pch=NULL, ylab= \"density\", main=\"Distribution null hypothesis and alternative\", yaxt=\"n\") polygon(c(seq(6, 6.5, 0.005),0), c(dnorm(seq(6, 6.5, 0.005), mean =mean_set2, sd=sqrt(var(set2)/100)),0), col=\"lightblue\") curve(dnorm(x, mean=6.2, sd= sqrt(var_NorA)), col=\"#f4c2c2\", lwd=2,add=T) curve(dnorm(x, mean=6.2, sd= sqrt(var_NorA/100)),n=500, col=\"red\", lwd=2,add=T) curve(dnorm(x, mean=mean_set2, sd= sqrt(var(set2))), col=\"#d2d1f9\", lwd=2,add=T) curve(dnorm(x, mean=mean_set2, sd= sqrt(var(set2)/100)), n=500,col=\"purple\", lwd=2,add=T) abline(v=mean_set2, col=\"#d2d1f9\" ) abline(v=6.2, col=\"#f4c2c2\", lwd=2 ) lines(c(6.1699, 6.4054), c(5,5)) The figure above show the hypothetical population around the sample mean from our sample (shaded blue color) and its relation to true sampling distribution of mean (red). Also at the bottom somewhat flat is the distribution of height. The black line is the 95% confidence interval and even for this sample we can see the true population mean lies within this interval. Is the average height of male (Age group 20-39 years old) in North America different than in Europe or Asia ? This is the question about comparing two populations of sample means. Therefore we need to polish our approach little bit. We now know that, for each populations we can build a sampling distribution of sample means, them mean of such distribution is the true mean of the population. When we need to compare two population we will have two such distributions of sampling means. As we have see so far, ultimately, we will need only one distribution and a value to see how uncommon it is in that distribution. Therefore, in case of comparing two populations we need to first find distribution for a random variable which is the difference between the sample means of two populations. The random variable \\(\\bar Y_1 - \\bar Y_2\\) also follows t-distribution and the t-statistic for large sample size is calculated by this formula: \\[t = \\frac{\\bar y1- \\bar y_2}{\\sqrt{\\frac {s_1^2}{n1}+\\frac{s_2^2}{n_2}}}\\] set.seed(500) ## is there difference between N. America and Asia cat(\"####----T-test between N America and Asia---------######\\n\") ## ####----T-test between N America and Asia---------###### Sample_NAmerica &lt;- sample(NorA, 50) Sample_Asia &lt;- sample(Asia, 50) t.test(Sample_Asia, Sample_NAmerica, ) ## ## Welch Two Sample t-test ## ## data: Sample_Asia and Sample_NAmerica ## t = -17.984, df = 69.395, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.306438 -1.045557 ## sample estimates: ## mean of x mean of y ## 5.006745 6.182742 ## see for N. America and Europe cat(\"####----T-test between N America and Europe---------######\\n\") ## ####----T-test between N America and Europe---------###### Sample_Euro &lt;- sample(Euro, 50) t.test(Sample_Euro, Sample_NAmerica) ## ## Welch Two Sample t-test ## ## data: Sample_Euro and Sample_NAmerica ## t = -6.0688, df = 92.631, p-value = 2.792e-08 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.6059330 -0.3071451 ## sample estimates: ## mean of x mean of y ## 5.726203 6.182742 Conclusions: Using the methods of inference we are able estimate the population parameters with much more accuracy even with very small amount of data. This note provides only the overview of different hypothesis testing possible in statistics but hope this provided a clear concept of big picture of what is going on when we do a hypothesis testing."
    }
  ]
}</script>


<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<link href="/assets/css/main.css" rel="stylesheet"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v0.4.1/dist/bootstrap-toc.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.css">
<link href="/assets/css/nav-media.css" rel="stylesheet">

  </head>

  <body >
    <script src="/assets/js/color-scheme-attr-init.js" data-mode="false"></script>
    <nav class="navbar navbar-default top-nav">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle collapsed pull-left top-nav-menu-toggle" data-toggle="collapse" data-target="#id_top-nav-menu-toggle" aria-expanded="false">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand top-nav-brand" href="/" translate="no">Data churn by AK</a>
    </div>
  <div class="color_scheme_switch_top_holder" data-toggle="tooltip" data-placement="bottom" title="Color scheme">
  <label class="color-scheme-switch hover-effect">
    <input type="checkbox" class="checkbox_color_switch" />
    <span></span>
  </label>
</div>

  
</nav>
<nav id="side-nav-container">
  <div class="side-nav">
    <div class="side-nav-brand">
      <img src="/assets/img/default/profile.jpg" alt="">
      <div class="brand-holder">
        <a href="/" translate="no">Data churn by AK</a>
        </div>
      <p>&nbsp;Data blogs</p>
      <br>
    </div>
    <br>
    <a href="javascript:void(0);" class="side-nav-close">
        <i class="fa fa-angle-double-left fa-2x" aria-hidden="true"></i>
      </a>
    <hr>
    <br>
    <div class="side-nav-buttons">
      <ul class="nav nav-pills nav-stacked">
        <li ><a href="/" class=" hover-effect"><i class="fa-fw fa fa-home" aria-hidden="true"></i>Home</a></li><li ><a href="/tabs/blog/" class="active-page hover-effect"><i class="fa-fw fa fa-pencil-square-o" aria-hidden="true"></i>Notes</a></li><li ><a href="/tabs/archive.html" class=" hover-effect"><i class="fa-fw fa fa-archive" aria-hidden="true"></i>Archive</a></li><li ><a href="/tabs/projects.html" class=" hover-effect"><i class="fa-fw fa fa-book" aria-hidden="true"></i>Notebooks</a></li><li ><a href="/tabs/links.html" class=" hover-effect"><i class="fa-fw fa fa-link" aria-hidden="true"></i>Links</a></li><li ><a href="/tabs/about.html" class=" hover-effect"><i class="fa-fw fa fa-user-o" aria-hidden="true"></i>About</a></li></ul>
    </div>
    <br>
    <br><div class="contact-container">
  <hr>
  <h3>Contact</h3>
  <ul><li><a href="https://www.github.com/akoirala2000" class="hover-effect-big" target="_blank" rel="noopener noreferrer"><i class="fa fa-github" aria-hidden="true"></i></a></li><li>
      <a href="javascript:void(0);" class="hover-effect-big" onclick="setAddress('datachurnbyak', 'gmail.com');"><i class="fa fa-envelope-o" aria-hidden="true"></i></a></li><li><a href="https://www.linkedin.com/in/amrit-koirala-41037392" class="hover-effect-big" target="_blank" rel="noopener noreferrer"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li><li><a href="https://www.twitter.com/amritkoirala1" class="hover-effect-big" target="_blank" rel="noopener noreferrer"><i class="fa fa-twitter" aria-hidden="true"></i></a></li></ul>
</div>

    <hr id="toc-view-top">
    <div class="side-nav-footer" translate="no">
        <p>&copy; 2022 Data churn by AK.</p>
      </div>
  </div>
  <div class="side-nav-bottom-buttons-container">
    <hr>
    <ul>
      <li><div class="color_scheme_switch_side_holder" data-toggle="tooltip" data-placement="top" title="Color scheme">
  <label class="color-scheme-switch hover-effect">
    <input type="checkbox" class="checkbox_color_switch" />
    <span></span>
  </label>
</div>
</li><li><div class="cookie-icon hover-effect" onclick="CookieConsent.showSettings();" data-toggle="tooltip" data-placement="top" title="Cookie settings">
  <div class="cookie-wrapper">
    <i class="fa fa-circle bitten-cookie" aria-hidden="true"></i>
    <i class="fa fa-circle small-ellipse-icon" aria-hidden="true"></i>
    <i class="fa fa-spinner inner-icon" aria-hidden="true"></i>
    <i class="fa fa-circle-thin outer-icon" aria-hidden="true"></i>
  </div>
</div>
</li></ul>
  </div></nav>
<div id="toc-container" class="movable">
  <div class="panel panel-default">
    <div class="panel-heading" data-toggle="tooltip" data-placement="top" title="Drag to move">
      Contents
      <span class="pull-right">
        <a href="javascript:void(0);" class="close-button" onclick="document.getElementById('toc-container').style.display = 'none';">
          <i class="fa fa-times" data-toggle="tooltip" data-placement="bottom" title="Close"></i>
        </a>
      </span>
    </div>
    <div class="panel-body">
      <nav id="table-of-contents"></nav>
    </div>
  </div>
</div>
<div id="main-wrapper">
      <div class="main-container"><div class="multipurpose-container post-container">
  <div class="post-title">Principle of inference</div><div class="meta">
  <small>
    &nbsp;<i class="fa fa-calendar"></i>&nbsp;&nbsp;Jan 12, 2022
  </small>
  <small>
    &nbsp;&nbsp;&nbsp;<span><i class="fa fa-clock-o"></i>&nbsp;32 min read</span>
  </small>
  
  <small class="meta-link" >
    &nbsp;&nbsp;&nbsp;<i class="fa fa-comments-o"></i>&nbsp;<a href="/posts/2022-01-13-Principle-of-inference#disqus_thread">-</a>
    <a href="javascript:void(0);" onclick="window.location.href='/posts/2022-01-13-Principle-of-inference#disqus_thread'">Comments</a>
  </small>
  </div>
<hr/>
  <div class="markdown-style">
    <h3 id="introduction">Introduction</h3>

<blockquote>
  <ol>
    <li>Is the height of male (Age group 20-39 years old) in North America
greater than 5.5 ?</li>
  </ol>
</blockquote>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America greater than 5.5 ?</li>
  </ol>
</blockquote>

<blockquote>
  <ol>
    <li>What is the average height of male (Age group 20-39 years old) in
North America, Europe, and Asia ?</li>
  </ol>
</blockquote>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America different than in Europe or Asia ?</li>
  </ol>
</blockquote>

<p>We often see similarly formatted questions statistics and use the
concepts of inference and hypothesis testing to solve them. <!-- outline-start -->Inference
and Hypothesis testing are the two most important and the most confusing
concepts in statistics. Inference is related to estimating the
population parameters from a sample. Hypothesis testing as its name
suggests is a two step process, first is to build a hypothesis and
second is to test how well our data support that hypothesis.<!-- outline-end -->
 Inference
and hypothesis testing are highly interdependent on each other because
the need to build a hypothesis before testing rises because we had to
use inference in the first place. Therefore, the best way to understand
them is by learning them together but understanding the fine differences
between each other at the same time. We will decipher this mystery by
solving to questions listed above by two different approach. First
approach is a hypothetical situation where we will not use any inference
and study the whole population while in the second approach we will do
orthodox sampling and hypothesis testing.</p>

<h4 id="without-using-inference">Without using inference</h4>

<blockquote>
  <p><em>Population is a data set representing all the entity of interest.</em>
For example: If we are interested in study of distribution of facebook
users by country then, all 2.912 billion facebook users (facebook data
2022) constitute the population. At the same time if we are interested
in distribution of facebook users in USA by state, then the facebook
users in USA (307.34 million) constitute the population. Similarly, if
we are interested in effect of age on hypertension in human being,
then every single human being in world (7.9 billion, 2022) constitute
our population. In situations where we are interested in small
population like comparing the performance of two high school senior
students only, we can make measurement on all students and compare the
mean performance score in each school but such study will have very
narrow scope and that result cannot be generalized to any other
schools. Measurements made on a population are called parameters and
mean is denoted by \(\mu\) and variance is denoted as \(\sigma^2\).</p>
</blockquote>

<p>Now lets dive into our questions. If we are not going to use inference
then we do not have our favorite option of sampling, we are forced to
study the whole population. After some google search I could figure out
that there are 450, 105 and 75 million males of this age group in Asia,
Europe and North America respectively and each of these constitute a
population for this question. Therefore, we will first need to find the
height of each of these millions of people from each continent. We can
simulate such population in R by generating a dummy population of such
size and also calculate the mean, standard deviation and distribution
for each population (Figure 1). Even for R, processing such large sized
vector took quite a while, imagine you had to do this in reality. How
much resource, money, time, and bookkeeping you would need to accomplish
this?</p>

<div class="panel-group">
  <div class="panel panel-default" style="white-space: normal; overflow-x: auto; ">
        <button data-toggle="collapse" data-target="#toggle-code1">
           code here 
        </button>
    </div>
    <div id="toggle-code1" class="panel-collapse collapse">
      <div class="panel-body">
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">578</span><span class="p">)</span><span class="w">
</span><span class="n">Asia</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">4.5e8</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">)</span><span class="w">
</span><span class="n">NorA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">7.5e+07</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="m">0.4</span><span class="p">)</span><span class="w">
</span><span class="n">Euro</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="m">1.05e+08</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="w"> </span><span class="m">5.7</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w">
</span><span class="n">mean_Asia</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">Asia</span><span class="p">)</span><span class="w">
</span><span class="n">var_Asia</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">var</span><span class="p">(</span><span class="n">Asia</span><span class="p">)</span><span class="w">
</span><span class="n">hist_asia</span><span class="w"> </span><span class="o">&lt;-</span><span class="n">hist</span><span class="p">(</span><span class="n">Asia</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">200</span><span class="p">,</span><span class="w"> </span><span class="n">plot</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">

</span><span class="n">mean_NorA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">NorA</span><span class="p">)</span><span class="w">
</span><span class="n">var_NorA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">var</span><span class="p">(</span><span class="n">NorA</span><span class="p">)</span><span class="w">
</span><span class="n">hist_NorA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">hist</span><span class="p">(</span><span class="n">NorA</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="w"> </span><span class="m">200</span><span class="p">,</span><span class="w"> </span><span class="n">plot</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">

</span><span class="n">mean_Euro</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">Euro</span><span class="p">)</span><span class="w">
</span><span class="n">var_Euro</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">var</span><span class="p">(</span><span class="n">Euro</span><span class="p">)</span><span class="w">
</span><span class="n">hist_Euro</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">hist</span><span class="p">(</span><span class="n">Euro</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="w"> </span><span class="m">200</span><span class="p">,</span><span class="w"> </span><span class="n">plot</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">


</span><span class="n">plot</span><span class="p">(</span><span class="n">hist_asia</span><span class="p">,</span><span class="w"> </span><span class="n">border</span><span class="o">=</span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4.2</span><span class="p">,</span><span class="m">7.5</span><span class="p">),</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Continent"</span><span class="p">,</span><span class="w"> 
     </span><span class="n">main</span><span class="o">=</span><span class="s2">"Distribution of height of male aged 20-39 in 3 different continents"</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">hist_NorA</span><span class="p">,</span><span class="w"> </span><span class="n">border</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">hist_Euro</span><span class="p">,</span><span class="w"> </span><span class="n">border</span><span class="o">=</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span><span class="n">legend</span><span class="p">(</span><span class="m">5.5</span><span class="p">,</span><span class="m">8e6</span><span class="p">,</span><span class="w"> 
       </span><span class="n">legend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Asia (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_Asia</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Asia</span><span class="p">),</span><span class="m">3</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">),</span><span class="w">
                           </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Europe (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_Euro</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Euro</span><span class="p">),</span><span class="m">1</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">),</span><span class="w">
                           </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"North America (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_NorA</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="p">),</span><span class="m">1</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">)),</span><span class="w">
       </span><span class="n">fill</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="w"> </span><span class="s2">"red"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>
</div>
      <div class="panel-footer">done!</div>
  </div>
</div>

<p><img class="lozad imgViewer mfp-zoom" data-mfp-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-1-1.svg" data-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-1-1.svg" alt="" /></p>

<p>For now lets assume, R did all that hard work for us and we have
necessary data we wanted to collect and we can focus on the answers to
the question above:</p>

<blockquote>
  <ol>
    <li>Is the height of male (Age group 20-39 years old) in North America
greater than 5.5 ?</li>
  </ol>
</blockquote>

<p>We can see from figure 1 that most of the heights in North America is
greater than 5.5. It may be tempting to answer “Yes” to this question
but if we do so, we will be wrong because all the heights in North
America are not above 5.5 (there is small proportion of heights in N
America below 5.5). The alternative is to first calculate the
probability of finding a height less than 5.5 (\(\alpha\)) in N America
and re-phrase our answer as “the height in N America is greater than 5.5
but the probability that this is incorrect is \(\alpha\). The smaller
this \(\alpha\) aka <strong>significance level</strong> or <strong>p-value</strong> gets there is
more certainty in our answer. The generally acceptable value of
\(\alpha\) is &lt; 0.05. Since, we already know mean and sd of all these
three population we can plug these number in pdf of normal distribution
in R to find these p-values and also visualize the probability we are
calculating as the area under the curve (figure 2). For details about
probability distribution and how to calculate probabilities for normally
distributed random variable see my notes on <a href="">normal distribution</a> and
<a href="">binomial distribution</a>).</p>

<div class="panel-group">
  <div class="panel panel-default" style="white-space: normal; overflow-x: auto; ">
        <button data-toggle="collapse" data-target="#toggle-code2">
           code here 
        </button>
    </div>
    <div id="toggle-code2" class="panel-collapse collapse">
      <div class="panel-body">
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="p">(</span><span class="s2">"Probability that heights in N. America is less that 5.5 is = "</span><span class="p">,</span><span class="w">
</span><span class="n">pnorm</span><span class="p">(</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="w"> </span><span class="n">mean_NorA</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="p">)),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="p">(</span><span class="s2">"Probability that heights in Europe is less that 5.5 is = "</span><span class="p">,</span><span class="w">
</span><span class="n">pnorm</span><span class="p">(</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="w"> </span><span class="n">mean_Euro</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Euro</span><span class="p">)),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="p">(</span><span class="s2">"Probability that heights in Asia is less that 5.5 is = "</span><span class="p">,</span><span class="w">
</span><span class="n">pnorm</span><span class="p">(</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="w"> </span><span class="n">mean_Asia</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Asia</span><span class="p">)),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.2</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="n">to</span><span class="o">=</span><span class="w"> </span><span class="m">7.5</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s2">"height(in)"</span><span class="p">)</span><span class="w">
</span><span class="n">polygon</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="m">5.5</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.2</span><span class="p">),</span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"lightblue"</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5.7</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.3</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">polygon</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="m">5.5</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="m">5.7</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.3</span><span class="p">),</span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"lightgreen"</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.4</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">polygon</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="m">5.5</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.05</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.4</span><span class="p">),</span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">0.2</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">legend</span><span class="p">(</span><span class="m">5.6</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="w"> 
       </span><span class="n">legend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Asia (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_Asia</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Asia</span><span class="p">),</span><span class="m">3</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">),</span><span class="w">
                           </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"Europe (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_Euro</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_Euro</span><span class="p">),</span><span class="m">1</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">),</span><span class="w">
                           </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"North America (mean = "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">mean_NorA</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="w"> </span><span class="s2">", sd= "</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="p">),</span><span class="m">1</span><span class="p">),</span><span class="s2">")"</span><span class="w"> </span><span class="p">)),</span><span class="w">
       </span><span class="n">fill</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="w"> </span><span class="s2">"red"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

</div>
      <div class="panel-footer">done!</div>
  </div>
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Probability that heights in N. America is less that 5.5 is =  0.04006165

## Probability that heights in Europe is less that 5.5 is =  0.2524402

## Probability that heights in Asia is less that 5.5 is =  0.9937895
</code></pre></div></div>

<p><img class="lozad imgViewer mfp-zoom" data-mfp-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-2-1.svg" data-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-2-1.svg" alt="" /></p>

<p>Using the p-values we can now give the complete answer; Yes, the height
of male (Age group 20-39 years old) in N America is greater than 5.5 ft,
given that this may be wrong 4% of the time. This 4% is below the
generally accepted level of 5% error rate. Therefore, if a jeans
manufacturer in N. America makes pants for height only above 5.5 ft,
majority of man in N. America can find pants of their size. While a
similar company in Europe would never want to manufacture pants that fit
only above 5.5 ft because one fourth of its customers won’t be able to
use that. Similarly, such company in Asia will manufacture pants that
will fit heights less than 5.5 ft only. Therefore, although the answer
we get using statistics may sound like incomplete information it has a
lot of practical application when the result needs to be implemented in
a large population.</p>

<p>Lets review what we did here because it forms the foundation of any
hypothesis testing. When the underlying distribution of a <a href="">random
variable</a> (Y) is known, for any value of that random variable (y), we
can find the probability of observing values more extreme than that
value(y). If that probability is very small, then we can say, that
value(y) itself is very rear in this distribution and could belong to
other distribution. To take an example from the problem we are working
with, we saw that probability getting a height greater than 5.5 in Asia
is extremely low (0.00063). Therefore, if we randomly sample a man from
the whole world and his height is found to be 5.5, then we can very
confidently (probability of error is only 0.00063) say he is not from
Asia. Does this mean he belong to N America? Or Europe? No, we will
never know that answer but the point is when we properly select the
random variable(Y) (sample mean, difference of sample mean, sample
variance, sample proportion etc. ) and ask the correct question we can
get some very useful answers about question of interest. Once we
understand this we will later see how aptly early statisticians have
devised hypothesis testing to get best out of it.</p>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America greater than 5.5 ?</li>
  </ol>
</blockquote>

<p>Since we have made measurements on every man in that age group we can
find the true mean by calculating sum of all the heights in a continent
and divide by the population size of that continent which R already did
for us. The mean height in N America is 6.2. This is true mean of this
population so we do not need to make any estimate or confidence
intervals to say that mean height in N America is greater that 5.5.</p>

<blockquote>
  <ol>
    <li>What is the average height of male (Age group 20-39 years old) in
North America, Europe, and Asia ?</li>
  </ol>
</blockquote>

<p>Similar to question no. 2, since we have complete population data, we
can say with 100% confidence that mean height in N America, Europe and
Asia is 6.2, 5.7 and 5 respectively.</p>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America different than in Europe or Asia ?</li>
  </ol>
</blockquote>

<p>Answer to this is also straight forward. From question no 3 we can see
clearly, they are different for these three populations.</p>

<p>We saw, many of these questions could be easily answered because we
could measure each and every man and get true mean \((\mu)\) and sd
\((\sigma)\) for these populations. But recall again how arduous that
task could be and the real-world situation is even more complicated by
the fact that most populations we need to study have infinite numbers of
entities, so it is impossible to find the true population parameters.</p>

<p>This is where inference shines in. Inference provides the unbiased
estimate of the population parameters using the information from a
sample of certain size (n) from that population. Now, that we know the
complications of studying the whole population we will see below, how we
can deal with our question in much practical way using principles of
inference and hypothesis testing, but first lets understand how
inference works in general.</p>

<h3 id="statistical-inference">Statistical inference</h3>

<blockquote>
  <p><em>sample is a subset of population (size = n) and is unbiased
representation of the population.</em> If n= \(\infty\), sample behaves
like the population and if n = 1, sample is just one observation from
the population. It is very important for sample to be a representative
of population because ultimately measurements made on a sample will be
used to infer the population parameter. Any measurements made on a
sample is called statistic (note statistics is branch of mathematics
which study these statistic). For example sample mean (\(\bar x\)) and
sample variance (\(s^2\))</p>
</blockquote>

<p>Sample is the main workhorse of statistics. This is all we have to make
inference about population parameters. Usually a sample used to make
inference on population parameters is much smaller in size than the
population itself so it is very convenient to collect data (statistic)
on a sample but this convenience comes at some cost, which is
uncertainty associated with the estimate. We will see later, this
uncertainty depend on population variance and we can tackle it by
increasing sample size (n). <strong>Fortunately, in many real life situation,
a sample of small size gives an estimate of population parameters with
high precision</strong>. Therefore in a statistical analysis, sample statistic
is used to make a statement about the population parameter which is
always accompanied by a degree of precision (or chances of making an
error). In situations where, the precision is relatively high (chances
of making an error is low) we trust that statement and interpret our
experiment based off that statement about population. On the other hand,
if precision is low (chances of making an error is high), we do not
trust that statement about population, so we cannot make any
interpretation about the experiment or question of interest. The widely
accepted level of that accuracy in scientific community is above 95% (or
less than 5% chances of making an error).</p>

<h4 id="inference-framework">Inference framework</h4>

<p>Statistical inference uses very complex mathematical models to build a
framework which will take the information from a sample of finite size
(n) as an input and output estimate of parameters for the population of
infinite size (along with degree of uncertainty). Then we can use these
estimates of population parameters for the purpose of hypothesis testing
or other interpretation downstream. Although, we are not interested in
details of the mathematical models we must see what are the major
components of this framework and how it process the information from a
sample and what assumptions must be satisfied for the results from this
framework to be valid.</p>

<div class="panel-group">
  <div class="panel panel-default" style="white-space: normal; overflow-x: auto; ">
        <button data-toggle="collapse" data-target="#toggle-code3">
           code here 
        </button>
    </div>
    <div id="toggle-code3" class="panel-collapse collapse">
      <div class="panel-body">
<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#population defined by mean and variance </span><span class="w">
</span><span class="n">poplist</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">pop1</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">0.04</span><span class="p">)</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">pop2</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5.7</span><span class="p">,</span><span class="w"> </span><span class="m">0.0898</span><span class="p">),</span><span class="w"> </span><span class="n">pop3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="m">0.1599</span><span class="p">))</span><span class="w">
</span><span class="n">pop_col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"blue"</span><span class="p">,</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w">
  
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="m">7.5</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Distribution of 3 populations"</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">poplist</span><span class="p">)){</span><span class="w">
  </span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">2</span><span class="p">])),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="n">pop_col</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Standardized normal curve</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-4</span><span class="p">,</span><span class="n">to</span><span class="o">=</span><span class="w"> </span><span class="m">+4</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="w"> </span><span class="s2">"z"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="w"> </span><span class="s2">"Standard normal distribution"</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Sampling distribution of sample mean</span><span class="w">
</span><span class="n">sample_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="m">25</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">sample_colors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">pop1</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"#89CFF0"</span><span class="p">,</span><span class="s2">"#6495ED"</span><span class="p">,</span><span class="s2">"#6082B6"</span><span class="p">,</span><span class="s2">"#5D3FD3"</span><span class="p">),</span><span class="w">
                      </span><span class="n">pop2</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"#AFE1AF"</span><span class="p">,</span><span class="s2">"#50C878"</span><span class="p">,</span><span class="s2">"#008000"</span><span class="p">,</span><span class="s2">"#355E3B"</span><span class="p">),</span><span class="w">
                      </span><span class="n">pop3</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"#F88379"</span><span class="p">,</span><span class="s2">"#C04000"</span><span class="p">,</span><span class="s2">"#E30B5C"</span><span class="p">,</span><span class="s2">"#A52A2A"</span><span class="p">))</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="m">7.5</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">13</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="n">xlab</span><span class="o">=</span><span class="s2">"sample mean"</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Sampling distribution of sample mean"</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">poplist</span><span class="p">)){</span><span class="w">
  </span><span class="k">for</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)){</span><span class="w">
  </span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">2</span><span class="p">]</span><span class="o">/</span><span class="n">sample_size</span><span class="p">[</span><span class="n">sample</span><span class="p">])),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="n">sample_colors</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="n">sample</span><span class="p">],</span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">###sampling distribution of sample variance </span><span class="w">
</span><span class="c1"># When sample size is close to 30 or more chi square distribution is similar to normal distribution</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0.4</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">24</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="n">xlab</span><span class="o">=</span><span class="s2">"sample variance"</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Sampling distribution of sample varaince "</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">poplist</span><span class="p">)){</span><span class="w">
  </span><span class="k">for</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">3</span><span class="o">:</span><span class="m">4</span><span class="p">){</span><span class="w">
  </span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">((</span><span class="n">poplist</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="m">2</span><span class="p">])</span><span class="o">^</span><span class="m">2</span><span class="o">/</span><span class="p">(</span><span class="n">sample_size</span><span class="p">[</span><span class="n">sample</span><span class="p">]</span><span class="m">-1</span><span class="p">)</span><span class="o">*</span><span class="m">2</span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="n">sample_colors</span><span class="p">[[</span><span class="n">i</span><span class="p">]][</span><span class="n">sample</span><span class="p">],</span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">####Plot chisquare for distribution </span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">65</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0.2</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="n">xlab</span><span class="o">=</span><span class="s2">"Chi square"</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Chi-square distribution "</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="n">linecol</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rainbow</span><span class="p">(</span><span class="m">4</span><span class="p">)</span><span class="w">
</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">15</span><span class="p">,</span><span class="m">25</span><span class="p">,</span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">size</span><span class="p">)){</span><span class="w">
    </span><span class="n">curve</span><span class="p">(</span><span class="n">dchisq</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="m">-1</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="n">to</span><span class="o">=</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="n">linecol</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="n">legend</span><span class="p">(</span><span class="m">30</span><span class="p">,</span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="n">legend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"df = "</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="m">-1</span><span class="w"> </span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">linecol</span><span class="p">),</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">###Plot t-distribution </span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-4</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">0.4</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="n">xlab</span><span class="o">=</span><span class="s2">"t-statistic"</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"t-distribution "</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="n">linecol</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rainbow</span><span class="p">(</span><span class="m">4</span><span class="p">)</span><span class="w">
</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">15</span><span class="p">,</span><span class="m">25</span><span class="p">,</span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">size</span><span class="p">)){</span><span class="w">
  </span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-4</span><span class="p">,</span><span class="n">to</span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">)</span><span class="w">
    </span><span class="n">curve</span><span class="p">(</span><span class="n">dt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="m">-1</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-4</span><span class="p">,</span><span class="n">to</span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="n">linecol</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="n">legend</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">0.4</span><span class="p">,</span><span class="w"> </span><span class="n">legend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"Std. Normal"</span><span class="p">,</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"df = "</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="m">-1</span><span class="w"> </span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"darkgreen"</span><span class="p">,</span><span class="n">linecol</span><span class="p">),</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##### F-distribution </span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1.5</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="n">xlab</span><span class="o">=</span><span class="s2">"F-statistic"</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"F-distribution "</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="n">linecol</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rainbow</span><span class="p">(</span><span class="m">4</span><span class="p">)</span><span class="w">
</span><span class="n">size1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">15</span><span class="p">,</span><span class="m">25</span><span class="p">,</span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">size2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="m">23</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">size</span><span class="p">)){</span><span class="w">
    </span><span class="n">curve</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">df1</span><span class="o">=</span><span class="n">size1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="o">=</span><span class="n">size2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="m">-1</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="n">linecol</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">1.7</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="n">legend</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">legend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="w"> </span><span class="n">paste0</span><span class="p">(</span><span class="s2">"df1 = "</span><span class="p">,</span><span class="w"> </span><span class="n">size1</span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="s2">", df2 = "</span><span class="p">,</span><span class="w"> </span><span class="n">size2</span><span class="m">-1</span><span class="w">  </span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">linecol</span><span class="p">),</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

</div>
      <div class="panel-footer">done!</div>
  </div>
</div>

<p>We need to acknowledge that population parameters (\(\mu\)) and
(\(\sigma^2\)) are fixed and universal quantity and we will never know
its true value (We will use the true population parameters calculated in
first step to compare results from the inference only). The ultimate
goal of inference is to get best estimate of these two parameters using
only statistic calculated from a sample of size n. The major components
of the statistical framework are shown in figure 3. The population with
mean (\(\mu\)) and variance (\(\sigma^2\)) is on the top of this
framework and it is represented by distribution of random variable we
are interested in (Example height of male aged between 20-39). The most
important assumption about the population is that it follows normal
distribution hence a standard normal distribution curve can be used to
find probabilities related to the population.</p>

<p>Two most important statistic we measure on a sample is sample mean
\((\bar x)\) and sample variance \((s^2)\). <strong>Central Limit Theorem</strong>
gives the distribution of <a href="">sampling distribution of sample mean</a> which
states that sample mean are also normally distributed and mean of such
distribution is also population mean (\(\mu\)), but has less variance
than the population variance (figure 3) given by \(\frac{\sigma^2}{n}\).
Therefore, larger the sample size gets less is the variance (shown by
darker color for each population in figure 3). To get the probability
associated with this distribution we can do a z-scale transformation for
which we need population mean \(\mu\) and population variance
\(\sigma^2\).</p>

<p>\(z= \frac{\bar Y- \mu}{\frac{\sigma}{\sqrt n}}\) Hypothesis testing is
designed in such a way that we will our question will have the
population mean but we should be able to estimate the population
variance using the sample variance. The top left plot in figure 3 show
the distribution of sample variance. It is found that sample variance
follows <a href="">Chi-squared \(\chi ^2\) distribution</a>. Which shows, mean of
the distribution of sample variance is population variance but unlike
when the sample size is small it is heavily skewed on the left. Which
means sample variance calculated from a random sample of small size most
probably gives the underestimate of the population variance.
\(\chi ^2\) distribution accounts for this discrepancy by providing
separate distribution for samples of different size. To include this
information in our z-score calculation a new statistic is calculated
called t-statistic which follows <a href="">t-distribution</a> and similar to
\(\chi^2\) distribution it has different distribution for different
sample size. Both \(\chi^2\) and t-distribution is same as normal
distribution when that sample size is greater than 30. Once we have this
t-statistic we can use the probability given by t-distribution to find
any probability associated with sampling distribution of sample means.</p>

\[t-statistic = \frac{\bar Y- \mu}{\frac{s}{\sqrt n}}\]

<p>As you can see the all the variables in the equation can be calculated
using a sample which enables us to compare the sample mean with the mean
given in the question.</p>

<p>The above method works best only when we need to compare two means. When
we need to compare means from more than one population ANOVA is used for
which inference framework has F-distribution which is basically ratio of
two variance. If the variance is equal it has a value of 1 other wise it
will be greater than 1. Details in <a href="">ANOVA</a>.</p>

<p><img class="lozad imgViewer mfp-zoom" data-mfp-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png" data-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/Alldistributions.png" alt="Relationship between distributions used in inference" /></p>

<h4 id="application">Application</h4>

<p>Now that we have seen the basic components of inference (please see
notes focused on each distribution to learn more about them) we can
again revisit our questions.</p>

<blockquote>
  <ol>
    <li>Is the height of male (Age group 20-39 years old) in North America
greater than 5.5 ?</li>
  </ol>
</blockquote>

<p>We could answer this question in much detail when we had the
distribution of heights (defined by population mean and variance) in
hand. But now we do not know population parameters hence inference is
not able to provide answer to this question but we can still answer
other questions below.</p>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America greater than 5.5 ?</li>
  </ol>
</blockquote>

<p>Lets recall what we learned about hypothesis testing in the beginning.
If we know the underlying distribution of a random variable we can
check, how unusual a given value is to that distribution and if it is
indeed very rare to observe that value in given distribution we can
conclude, that value does not belong to the given distribution. In
hypothesis testing we do exactly same but in little twisted way to be
able to use the inference framework discussed above. In this setup we
make a null hypothesis and it is exactly opposite to what we want in our
question of interest. So why we need this null hypothesis? To answer
this, lets see what is our question and what information we have about
our population. Since we are not measuring every man living in N
America, all we can do is measure heights in a randomly selected sample
of size(n). Then, the mean we calculate from this sample(\(\bar x\)) is
just one value in the sampling distribution of the sample mean for this
population. We cannot calculate t-statistic with just sample mean and
sample variance. We need the population mean. The question is giving us
some clue. We need to first see that there are two populations in this
question. The height of male (Age group 20-39 years old) in N America is
first and obvious population we have been seeing from the beginning but
the number we are tying to compare (5.5) is actually mean of a
hypothetical population. Therefore, if we cannot find population mean
for our population, we can assume that our sample is taken from that
hypothetical population (for which mean is given by the question) and
check how unusual is this sample mean in that hypothetical population?
If it comes out to be a rare event than we can reach to the conclusion
that our sample does not belong to that hypothetical population.</p>

<p>What we are doing by assuming our sample came from that hypothetical
population given by question is building a null hypothesis. And at the
end of the test we want to see the sample mean we get from our sample,
to be a rare event for that hypothetical population. Which means we
reject null hypothesis.</p>

<p>To formally do this we first state the null hypothesis (\(H_o\)) and
alternate hypothesis (\(H_1\))</p>

\[H_o: \mu = 5.5\]

\[H_1: \mu &gt;5.5\]

<p>Then calculate the t-statistic
\(t =\frac{\bar x - 5.5}{\frac{s}{\sqrt n}}\)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Lets first make a sample of 100 from the population of NoA</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">45</span><span class="p">)</span><span class="w">
</span><span class="n">set1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">NorA</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"The t-statistic for this test is = "</span><span class="p">,(</span><span class="n">mean</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span><span class="m">-5.5</span><span class="p">)</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## The t-statistic for this test is =  18.31421
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="p">(</span><span class="w"> </span><span class="s2">"The p-value for this test is = "</span><span class="p">,</span><span class="n">pt</span><span class="p">((</span><span class="n">mean</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span><span class="m">-5.5</span><span class="p">)</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">),</span><span class="w"> </span><span class="m">99</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">),</span><span class="w"> </span><span class="s2">"\n \n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## The p-value for this test is =  7.324508e-34 
## 
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cat</span><span class="p">(</span><span class="s2">"##########--USING R t.test FUNCTION --########\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## ##########--USING R t.test FUNCTION --########
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t.test</span><span class="p">(</span><span class="n">set1</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="w"> </span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"greater"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##  One Sample t-test
## 
## data:  set1
## t = 18.314, df = 99, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is greater than 5.5
## 95 percent confidence interval:
##  6.147978      Inf
## sample estimates:
## mean of x 
##  6.212581
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##visualize </span><span class="w">
</span><span class="c1">##BIG ASSUMPTION JUST FOR VISUALIZATION </span><span class="w">
</span><span class="c1">#for hypothetical population the variance is assumed to be equal to sample variance (just an approximation to see big picture )</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">9</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">11</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Distribution null hypothesis and alternative"</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#f4c2c2"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="o">/</span><span class="m">100</span><span class="p">)),</span><span class="n">n</span><span class="o">=</span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set1</span><span class="p">))),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#d2d1f9"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set1</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">)),</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">500</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s2">"purple"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">

</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="m">5.5</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#d2d1f9"</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#f4c2c2"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">set1</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p><img class="lozad imgViewer mfp-zoom" data-mfp-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/ttestQ1.svg" data-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/ttestQ1.svg" alt="" /></p>

<p>In the figure 4 we can clearly see, why p-value is so small. The
distribution with green shade and the green dot at 6.21 are the only one
distribution and data that given to us by the question. The alternative
hypothesis and other populations are shown using the data we collected
from first section just to show big picture.</p>

<blockquote>
  <ol>
    <li>What is the average height of male (Age group 20-39 years old) in
North America, Europe, and Asia ?</li>
  </ol>
</blockquote>

<p>In absence of the knowledge of true population mean, the mean we get
from a sample is the best estimate of the true population mean. But
given the inherent variability in the sampling distribution of sample
means there will be some level of uncertainty. To account for this
instead of reporting the point estimate, we find a interval at certain
significance level based of the sample mean. Lets start with North
America, we will again randomly take a sample of size(n)= 50. And
calculate the sample mean of this sample. Since we do not know the
population mean, we will need to assume the population mean is sample
mean in this sample and based off the distribution centered around this
sample mean we will calculate the range of sample means which is
encompass 95% of the sample means(exclude only 2.5% means on both
extremes of distribution). Narrower this interval is better is the
quality. The interpretation for CI at 95% significane is 95% of the
times we construct such intervals, true means will be within that
interval.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">set2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">NorA</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">mean_set2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span><span class="w">
</span><span class="n">mean_set2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">qt</span><span class="p">(</span><span class="m">0.025</span><span class="p">,</span><span class="w"> </span><span class="m">49</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span><span class="o">/</span><span class="m">50</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 6.169956
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean_set2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">qt</span><span class="p">(</span><span class="m">0.025</span><span class="p">,</span><span class="w"> </span><span class="m">49</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="o">*</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span><span class="o">/</span><span class="m">50</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 6.405479
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Results can be confirmed by doing a test test for this mean</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">set2</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="w"> </span><span class="n">mean_set2</span><span class="p">,</span><span class="w"> </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"two.sided"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##  One Sample t-test
## 
## data:  set2
## t = 0, df = 49, p-value = 1
## alternative hypothesis: true mean is not equal to 6.287718
## 95 percent confidence interval:
##  6.169956 6.405479
## sample estimates:
## mean of x 
##  6.287718
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##visualize </span><span class="w">
</span><span class="c1">##BIG ASSUMPTION JUST FOR VISUALIZATION </span><span class="w">
</span><span class="c1">#for unknow population with mean equal to sample mean  the variance is assumed to be equal to sample variance (just an approximation to see big picture )</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">7.3</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">11</span><span class="p">),</span><span class="w"> </span><span class="n">pch</span><span class="o">=</span><span class="kc">NULL</span><span class="p">,</span><span class="w">  </span><span class="n">ylab</span><span class="o">=</span><span class="w"> </span><span class="s2">"density"</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Distribution null hypothesis and alternative"</span><span class="p">,</span><span class="w"> </span><span class="n">yaxt</span><span class="o">=</span><span class="s2">"n"</span><span class="p">)</span><span class="w">
</span><span class="n">polygon</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">6.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.005</span><span class="p">),</span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">seq</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">6.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.005</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="n">mean_set2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">)),</span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"lightblue"</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#f4c2c2"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var_NorA</span><span class="o">/</span><span class="m">100</span><span class="p">)),</span><span class="n">n</span><span class="o">=</span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">mean_set2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set2</span><span class="p">))),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#d2d1f9"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">
</span><span class="n">curve</span><span class="p">(</span><span class="n">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">mean_set2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">(</span><span class="n">set2</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">)),</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="m">500</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s2">"purple"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="n">add</span><span class="o">=</span><span class="nb">T</span><span class="p">)</span><span class="w">

</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="n">mean_set2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#d2d1f9"</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="m">6.2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"#f4c2c2"</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">lines</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">6.1699</span><span class="p">,</span><span class="w"> </span><span class="m">6.4054</span><span class="p">),</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">5</span><span class="p">))</span><span class="w">
</span></code></pre></div></div>

<p><img class="lozad imgViewer mfp-zoom" data-mfp-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-7-1.svg" data-src="/assets/img/posts/Principle-of-Infernce_files/figure-markdown/unnamed-chunk-7-1.svg" alt="" />
The figure above show the hypothetical population around the sample mean
from our sample (shaded blue color) and its relation to true sampling
distribution of mean (red). Also at the bottom somewhat flat is the
distribution of height. The black line is the 95% confidence interval
and even for this sample we can see the true population mean lies within
this interval.</p>

<blockquote>
  <ol>
    <li>Is the average height of male (Age group 20-39 years old) in North
America different than in Europe or Asia ?</li>
  </ol>
</blockquote>

<p>This is the question about comparing two populations of sample means.
Therefore we need to polish our approach little bit. We now know that,
for each populations we can build a sampling distribution of sample
means, them mean of such distribution is the true mean of the
population. When we need to compare two population we will have two such
distributions of sampling means. As we have see so far, ultimately, we
will need only one distribution and a value to see how uncommon it is in
that distribution. Therefore, in case of comparing two populations we
need to first find distribution for a random variable which is the
difference between the sample means of two populations. The random
variable \(\bar Y_1 - \bar Y_2\) also follows t-distribution and the
t-statistic for large sample size is calculated by this formula:</p>

\[t = \frac{\bar y1- \bar y_2}{\sqrt{\frac {s_1^2}{n1}+\frac{s_2^2}{n_2}}}\]

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">500</span><span class="p">)</span><span class="w">
</span><span class="c1">## is there difference between N. America and Asia </span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"####----T-test between N America and Asia---------######\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## ####----T-test between N America and Asia---------######
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sample_NAmerica</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">NorA</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">Sample_Asia</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">Asia</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">Sample_Asia</span><span class="p">,</span><span class="w"> </span><span class="n">Sample_NAmerica</span><span class="p">,</span><span class="w"> </span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##  Welch Two Sample t-test
## 
## data:  Sample_Asia and Sample_NAmerica
## t = -17.984, df = 69.395, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.306438 -1.045557
## sample estimates:
## mean of x mean of y 
##  5.006745  6.182742
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## see for N. America and Europe</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"####----T-test between N America and Europe---------######\n"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## ####----T-test between N America and Europe---------######
</code></pre></div></div>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sample_Euro</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">Euro</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">)</span><span class="w">
</span><span class="n">t.test</span><span class="p">(</span><span class="n">Sample_Euro</span><span class="p">,</span><span class="w"> </span><span class="n">Sample_NAmerica</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 
##  Welch Two Sample t-test
## 
## data:  Sample_Euro and Sample_NAmerica
## t = -6.0688, df = 92.631, p-value = 2.792e-08
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.6059330 -0.3071451
## sample estimates:
## mean of x mean of y 
##  5.726203  6.182742
</code></pre></div></div>

<h3 id="conclusions">Conclusions:</h3>

<p>Using the methods of inference we are able estimate the population
parameters with much more accuracy even with very small amount of data.
This note provides only the overview of different hypothesis testing
possible in statistics but hope this provided a clear concept of big
picture of what is going on when we do a hypothesis testing.</p>
<hr>
<div class="share-holder">
  <span class="share-label">Share on: </span>
  <ul class="share-buttons">
    
      <li>
        <a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F2022-01-13-Principle-of-inference&amp;text=Principle%20of%20inference%20-%20Data%20churn%20by%20AK" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" title="Twitter" class="hover-effect-big">
          <i class="fa fa-twitter-square fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
      <li>
        <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F2022-01-13-Principle-of-inference" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" title="Facebook" class="hover-effect-big">
          <i class="fa fa-facebook-square fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
      <li>
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F2022-01-13-Principle-of-inference&amp;text=Principle%20of%20inference%20-%20Data%20churn%20by%20AK" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" title="Telegram" class="hover-effect-big">
          <i class="fa fa-telegram fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
      <li>
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F2022-01-13-Principle-of-inference" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" title="LinkedIn" class="hover-effect-big">
          <i class="fa fa-linkedin-square fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
      <li>
        <a href="mailto:?subject=Principle%20of%20inference%20-%20Data%20churn%20by%20AK&amp;body=Principle%20of%20inference%20-%20Data%20churn%20by%20AK%20http%3A%2F%2Flocalhost%3A4000%2Fposts%2F2022-01-13-Principle-of-inference" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" title="Email" class="hover-effect-big">
          <i class="fa fa-envelope fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
      <li>
        <a href="javascript:void(0);" onclick="copyToClipboard('http://localhost:4000/posts/2022-01-13-Principle-of-inference', 'Link copied!')" id="copytoclipboard" data-toggle="tooltip" data-placement="top" title="Copy link" class="hover-effect-big">
          <i class="fa fa-link fa-fw" aria-hidden="true"></i>
        </a>
      </li>
    
  </ul>
</div>
</div>
</div>

    <div class="pagination_wrapper">
  <nav aria-label="Page navigation">
    <ul class="pagination" style="opacity:0">
    <li><a href="javascript:void(0);">1</a></li></ul>
  </nav>
</div>

  <div id="disqus_thread"></div>

<noscript>
  Please enable JavaScript to view the Comments.
</noscript>


</div><div class="footer-wrapper">
  <div class="footer-container">
    <footer translate="no">
      <div class="footer-text footer-text-centered long-copyright">
          <p>&copy; 2022 Data churn by AK. </p><a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" target="_blank" rel="noopener noreferrer" data-toggle="tooltip" data-placement="top" data-tooltip-no-hide title="Except where otherwise noted, content on this web site is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.">
              <img src="/assets/img/default/cc/cc.svg" alt="cc" width="12" height="12">&nbsp;<img src="/assets/img/default/cc/by.svg" alt="by" width="12" height="12">&nbsp;<img src="/assets/img/default/cc/sa.svg" alt="sa" width="12" height="12">&nbsp;<p>Some rights reserved.</p>
            </a></div>
      <p class="footer-powered"><span>Pwrd by </span><a href="https://github.com/MrGreensWorkshop/MrGreen-JekyllTheme" target="_blank" rel="noopener noreferrer">Mr. Green</a></p>
    </footer>
  </div>
</div>
<div class="scroll-to-top-container">
        <a id="scroll-to-top" href="#main-wrapper" class="hover-effect"><i class="fa fa-angle-up"></i></a>
      </div></div>

    <div class="searchbox-container">
  <form id="searchbox-form" >
    <input type="search" id="search-box" placeholder="Search"
    onkeyup="if(this.value!==''){document.getElementById('search-results').style.display = 'block';}"
    onfocusout="this.value='';"
    onblur="setTimeout(function(){ document.getElementById('search-results').style.display = 'none'; }, 100);">
    <ul id="search-results" ></ul>
  </form>
</div>


    <script src="https://code.jquery.com/jquery-3.6.0.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v0.4.1/dist/bootstrap-toc.min.js"></script>

<script src="/assets/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js"></script>
    <script>
      $('.imgViewer[data-no-image-viewer]').css("cursor", "unset");
      $(function () {
        $('.imgViewer:not([data-no-image-viewer])').magnificPopup({
          type: 'image'
          ,image: {
            titleSrc: 'alt'
            /* Error message */
            ,tError: 'The image could not be loaded.<br><br>%url%'
            /* Set to null to disable zoom out cursor. */
            /*,cursor: null */
          }
          ,closeOnContentClick: true
          ,showCloseBtn: false
          ,zoom: {
            /* By default it's false, so don't forget to enable it */
            enabled: true
            /* duration of the effect, in milliseconds */
            ,duration: 300
            /* CSS transition easing function */
            ,easing: 'ease-in-out'
          }
        });
      });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js"></script>
    <script>
      /* lazy loads elements with default selector as '.lozad' */
      const observer = lozad();
      observer.observe();
    </script>

<script>
      PagerPageNumbers.setProperties({
        paginatorListContainerName: ".pagination_wrapper .pagination"
        ,pageList: ["/posts/2022-01-13-Principle-of-inference", "/posts/2020-02-07-ChiSquare-Distribution", "/posts/2019-11-01-Expected-value", "/posts/2019-07-01-Degree-of-freedom", "/posts/2018-06-22-Permutation-n-Combination"]
        ,firstButtonName: 'First'
        ,lastButtonName: 'Last'
        ,prevButtonName: "«"
        ,nextButtonName: "»"
      });
    </script>



<script src="/assets/js/simple-jekyll-search-1.9.2.min.js"></script><script>
  function loadSearch(jsonData, searchParam) {
    if (!jsonData) jsonData = '/query/search.json';
    var searchInput = document.getElementById('search-box');

    const simpleJekyllSearch = SimpleJekyllSearch({
      searchInput: searchInput
      ,resultsContainer: document.getElementById('search-results')
      ,json: jsonData
      ,searchResultTemplate: '<li><a href="{url}">{title}<span>{date}</span></a></li>'
      ,noResultsText: '<li>No results found.</li>'
      ,limit: 10
      ,fuzzy: false
    });

    if (searchParam) {
      searchInput.value = searchParam;
      searchInput.focus();
      searchInput.disabled=false;
      setTimeout(function(){
        simpleJekyllSearch.search(searchParam);
      }, 400);
    }
  }

  </script>

<script>
    function isEmpty(value) {
      if (value === "" || value === null || typeof value === "undefined") return true;
      return false;
    }

    function getQueryParam (param, mach = true) {
      var queryString = window.location.search.substring(1);
      if (isEmpty(queryString)) return null;
      var queries = queryString.split("&");
      for (var i in queries) {
        var pair = decodeURIComponent(queries[i]).split("=");
        if (mach == true){
          if (pair[0] == param) {
            if (isEmpty(pair[1]) === false) return pair[1];
          }
        }else{
          return pair;
        }
        break;
      }
      return null;
    }

    const searchParam = getQueryParam('search');

    (async () => {
      let resp = await fetch('/query/search.json');
      if (!resp.ok) return;
      let jsonData = await resp.json();
      loadSearch(jsonData, searchParam);
    })();
  </script>
<script>
  const disqus_consent_msg = true;
  var disqus_config = function () {
    this.language = "en";
    this.page.url = 'http://localhost:4000/posts/2022-01-13-Principle-of-inference';
    this.page.identifier = '/posts/2022-01-13-Principle-of-inference';
  };

  function disqusLoader() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-datachurnbyak-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  }

  /* reload when data-color-scheme changes. (dark, light) */
  function disqusReloader() {
    if (typeof DISQUS === "undefined") return;
    DISQUS.reset({
      reload: true
      ,config: disqus_config
    });
  }
  const color_scheme_observer = new MutationObserver(disqusReloader);
  color_scheme_observer.observe(document.body, {attributeFilter: ["data-color-scheme"]});
  /* comments load mode */
  let discusLoadDoNotAskStorageKey = "disqusLoadDoNotAskAgain";

  function add_click_to_load_button() {
    if (localStorage.getItem(discusLoadDoNotAskStorageKey)) disqusLoader();

    /* create element */
    let newElement = document.createElement("div");

    if (disqus_consent_msg == true) {
      newElement.innerHTML = "<div class=\"multipurpose-container\" style=\"margin:20px\"> <h4 style=\"margin-top: 0;\">Comments (Disqus.com)</h4> <p> Comment feature is hosted by a third party. By showing the external content you accept the <a href=\"https://help.disqus.com/en/articles/1717102-terms-of-service\" target=\"_blank\" rel=\"noopener noreferrer\">Terms of Service</a> and <a href=\"https://help.disqus.com/en/articles/1717103-disqus-privacy-policy\" target=\"_blank\" rel=\"noopener noreferrer\">Privacy Policy</a> of disqus.com. <br>If you prefer to opt out of targeted advertising, open <a href=\"https://disqus.com/data-sharing-settings\" target=\"_blank\" rel=\"noopener noreferrer\">this link</a> and click \"opt-out\" button and close. Return here and load comments. </p> <a href=\"javascript:void(0);\" class=\"btn-base btn-priority load_comments\" data-comment-always-load role=\"button\">Always show</a> &nbsp;<a href=\"javascript:void(0);\" class=\"btn-base load_comments\" role=\"button\">Show only this time</a> </div>";
    } else {
      newElement.innerHTML = '<a href="javascript:void(0);" class="btn-base load_comments" role="button">Load Comments</a>';
      newElement.style.textAlign = 'center';
      newElement.style.minHeight = '20px';
    }

    /* add button */
    let holder = document.querySelector('#disqus_thread');
    if (!holder) return;
    holder.appendChild(newElement);
    /* add button click event */
    let buttons = document.querySelectorAll('#disqus_thread .load_comments');
    if (!buttons) return;
    buttons.forEach(function (button) {
      button.addEventListener('click', buttonCallback);
    });

    function buttonCallback(e) {
      disqusLoader();
      /* scroll to page bottom to see comments. */
      document.getElementById('disqus_thread').style.height = '394px';
      window.scrollTo(0, document.body.scrollHeight);
      if (e.target.hasAttribute('data-comment-always-load')) {
        localStorage.setItem(discusLoadDoNotAskStorageKey, true);
      }
    };
  }
  /* load when slide to the end of page */
  window.addEventListener("load", add_click_to_load_button);
  </script>


    <script id="dsq-count-scr" src="https://https-datachurnbyak-github-io.disqus.com/count.js" async></script>
    <script>
        if (window.location.hash == "#disqus_thread") {
          let element = document.getElementById('disqus_thread');
          $("html, body").animate({ scrollTop: $(element).offset().top }, 600);
        }
      </script>
     


<script>
  CookieConsent.consentSettingHtml = "<h5>Cookie settings</h5> <br> <p class=\"info-text\">This website uses cookies to optimize site functionality. It will be activated with your approval. Please click each item below for cookie policy. Check <a href=\"/privacy-policy.html\">Privacy policy</a> </p> <table> <tr> <td onclick=\"$('.info[data-consent-info=necessary]').slideToggle();$(this).children('i').toggleClass('fa-plus-square-o').toggleClass('fa-minus-square-o')\"> <i class=\"fa-fw fa fa-plus-square-o\" aria-hidden=\"true\"></i> <p>Strictly necessary cookies</p> </td> <td> <span class=\"active_text\">Always active</span></td> </tr> </table> <div class=\"info\" data-consent-info=\"necessary\"> <p>These cookies are essential for the website function and cannot be disable. They are usually set when site function like color scheme etc. is changed. These cookies do not store any personally identifiable information. Enables storage related to security such as authentication functionality, fraud prevention, and other user protection. </p> </div> <table> <tr> <td onclick=\"$('.info[data-consent-info=analytics]').slideToggle();$(this).children('i').toggleClass('fa-plus-square-o').toggleClass('fa-minus-square-o')\"> <i class=\"fa-fw fa fa-plus-square-o\" aria-hidden=\"true\"></i> <p>Performance cookies</p> </td> <td> <label class=\"slide-switch\"> <input type=\"checkbox\" class=\"checkbox_switch\" checked=\"checked\" data-consent=\"analytics\"> <span class=\"slider\"></span> </label></td> </tr> </table> <div class=\"info\" data-consent-info=\"analytics\"> <p>Enables storage (such as cookies) related to analytics e.g. visit duration. </p> </div> <table> <tr> <td onclick=\"$('.info[data-consent-info=preferences]').slideToggle();$(this).children('i').toggleClass('fa-plus-square-o').toggleClass('fa-minus-square-o')\"> <i class=\"fa-fw fa fa-plus-square-o\" aria-hidden=\"true\"></i> <p>Functionality cookies</p> </td> <td> <label class=\"slide-switch\"> <input type=\"checkbox\" class=\"checkbox_switch\" data-consent=\"preferences\"> <span class=\"slider\"></span> </label></td> </tr> </table> <div class=\"info\" data-consent-info=\"preferences\"> <p>Enables storage that supports the functionality of the website or app e.g. language settings. Enables storage related to personalization e.g. video recommendations. </p> </div> <table> <tr> <td onclick=\"$('.info[data-consent-info=advertising]').slideToggle();$(this).children('i').toggleClass('fa-plus-square-o').toggleClass('fa-minus-square-o')\"> <i class=\"fa-fw fa fa-plus-square-o\" aria-hidden=\"true\"></i> <p>Targeting and advertising cookies</p> </td> <td> <label class=\"slide-switch\"> <input type=\"checkbox\" class=\"checkbox_switch\" data-consent=\"advertising\"> <span class=\"slider\"></span> </label></td> </tr> </table> <div class=\"info\" data-consent-info=\"advertising\"> <p>Enables storage (such as cookies) related to advertising. </p> </div> <br> <div class=\"button-holder\"> <a href=\"javascript:void(0);\" class=\"btn-base btn-left\" onclick=\"CookieConsent.consentSettingDone('deny');\" role=\"button\">Deny</a> <a href=\"javascript:void(0);\" class=\"btn-base btn-priority\" onclick=\"CookieConsent.consentSettingDone('accept');\" role=\"button\">Allow all</a> <a href=\"javascript:void(0);\" class=\"btn-base \" onclick=\"CookieConsent.consentSettingDone('save');\" role=\"button\">Allow selection</a> </div>";
  CookieConsent.consentBarHtml = "<div class=\"consent-bar\"> <a class=\"close-button\" href=\"javascript:void(0);\" onclick=\"CookieConsent.hideConsentBar();\"><i class=\"fa-fw fa fa-times\"></i></a> <p>This website uses cookies to optimize site functionality. It will be activated with your approval. Check <a href=\"/privacy-policy.html\">Privacy policy</a> </p> <a href=\"javascript:void(0);\" class=\"btn-base \" onclick=\"CookieConsent.consentBarDone('deny');\" role=\"button\">Deny</a> <a href=\"javascript:void(0);\" class=\"btn-base \" onclick=\"CookieConsent.consentBarDone('settings');\" role=\"button\">Customize</a> <a href=\"javascript:void(0);\" class=\"btn-base btn-priority\" onclick=\"CookieConsent.consentBarDone('accept');\" role=\"button\">Allow all</a> </div>";
  CookieConsent.consent_items = JSON.parse('{"necessary":{"group":["security_storage"],"value":"granted","wait_for_update":500,"cookie_domain":"","no_check_box":true},"analytics":{"group":["analytics_storage"],"value":"denied"},"preferences":{"group":["functionality_storage","personalization_storage"],"value":"denied"},"advertising":{"group":["ad_storage"],"value":"denied"}}');
  CookieConsent.hideConsentBarWithSaveButton = true;

  const consent_settings = CookieConsent.getConsentSettings();
  const default_configs = JSON.parse('{"anonymize_ip":true,"ads_data_redaction":true,"cookie_flags":"SameSite=None;Secure"}');
</script>
</body>
</html>

